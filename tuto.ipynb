{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0cfb3e-76a6-4db1-a21f-f56e19872484",
   "metadata": {},
   "source": [
    "# Déploiement d'une application web sur SSP Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd74e5-b881-499c-a454-8617e2a1167e",
   "metadata": {},
   "source": [
    "Dans ce tutoriel, on explore le processus de déploiement d'une application web sur le SSP Cloud. Pour ce faire, on va suivre les étapes suivantes:\n",
    "- Conteneurisation de l'application\n",
    "- Déploiement sur SSP Cloud en utilisant un Helm Chart\n",
    "\n",
    "On s'intéresse particulièrement aux applications Python et R.\n",
    "Ce "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf4064f-9720-4d2c-8360-8630fee38893",
   "metadata": {},
   "source": [
    "## 1- Conteneurisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a871e49e-7d18-4d28-b365-2377af00e8c7",
   "metadata": {},
   "source": [
    "Pour pouvoir être déployée sur un cluster *Kubernetes*, une application doit nécessairement être mise à disposition sous la forme d'une image *Docker*. Concrètement, cette étape permet de rendre l'application portable : une fois que l'image Docker est construite et fonctionne correctement, elle peut être déployée sur n'importe quel environnement d'éxécution avec la certitude qu'elle fonctionnera de manière attendue, peu importe l'environnement qui a servi à la développer.\n",
    "\n",
    "Le fichier Dockerfile situé à la racine du projet contient une suite d'instructions qui permettent de conteneuriser l'application, sous la forme d'une image Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3567956-bde4-45cf-9ad0-adc6f9b65260",
   "metadata": {},
   "source": [
    "Dans cet premier exemple, on crée un Dockerfile pour une application web développée en Python avec Flask (le code source est disponible [**ici**](https://github.com/amine-bs/flask-tutorial))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de88f518-40c4-47e3-83fc-ec9a9f8e1e96",
   "metadata": {},
   "source": [
    "*<span style='color:RED'> FROM  </span> inseefrlab/onyxia-python-minimal:latest \n",
    "<br>\n",
    "<span style='color:RED'> COPY  </span> app ./\n",
    "<br>\n",
    "<span style='color:RED'> RUN  </span> pip install -r requirements.txt\n",
    "<br>\n",
    "<span style='color:RED'> EXPOSE  </span> 5000\n",
    "<br>\n",
    "<span style='color:RED'> ENTRYPOINT  </span> [\"flask\", \"--app\", \"main\", \"run\", \"--host\", \"0.0.0.0\", \"-p\", \"5000\"]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f300762-26ba-48fa-b19b-a8fd0cb92184",
   "metadata": {},
   "source": [
    "Le fichier contient 5 parties:\n",
    "- appel de l'image Docker de base: ``inseefrlab/onyxia-python-minimal``: Il s'agit d'une image de base contenant Python, les librairies systèmes, et les packages nécessaires au fonctionnement des applications Python. Elle est maintenue dans le cadre du projet Onyxia.\n",
    "- Copier le code de l'application dans l'image: On copie le code de l'application qui est dans le dossier ``app`` dans le directoire du travail de l'image.\n",
    "- Installation de dépendances de l'application dans l'image\n",
    "- Exposer le port utilisé par l'application: les applications Flask utilisent par défault le port 5000.\n",
    "- Entrypoint: c'est la commande de lancement du conteneur. Ici, ``main`` fait référence au fichier ``main.py``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca0deff-25b4-443a-8db7-13c07b587c60",
   "metadata": {},
   "source": [
    "Dans cet deuxième exemple, on suit les mêmes étapes pour créer un Dockerfile pour une application développée en R avec Shiny (le code source est disponible [**ici**](https://github.com/InseeFrLab/template-shiny-app))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb26b394-f634-4939-819c-e28d5fade20e",
   "metadata": {},
   "source": [
    "une fois l'image créée, nous devons la pousser vers un référentiel. Docker hub offre des dépôts publics qu'on peut utiliser gratuitement. Le push peut se faire avec la ligne de commande de Docker : docker push image. Mais c'est recommandé de mettre en place une intégration continue pour mettre à jour l'image automatiquement.*<span style='color:RED'> FROM  </span> inseefrlab/onyxia-r-minimal\n",
    "<br>\n",
    "#Install required linux librairies\n",
    "<br>\n",
    "<span style='color:RED'> ROOT  </span> root\n",
    "<br>\n",
    "<span style='color:RED'> RUN  </span> apt-get update -y && \\\n",
    "    apt-get install -y --no-install-recommends libpq-dev \\ \n",
    "                                               libssl-dev \\\n",
    "                                               libxml2-dev \\\n",
    "                                               gdal-bin \\\n",
    "                                               libgdal-dev\n",
    "<br>\n",
    "#Copy code\n",
    "<br>\n",
    "<span style='color:RED'> COPY  </span> myshinyapp/ ./myshinyapp\n",
    "<br>\n",
    "#Install dependencies\n",
    "<br>\n",
    "<span style='color:RED'> RUN  </span> Rscript -e 'remotes::install_deps(\"./myshinyapp\")'\n",
    "<br>\n",
    "<span style='color:RED'> RUN  </span> Rscript -e 'install.packages(\"./myshinyapp\", repos = NULL, type=\"source\")'\n",
    "<br>\n",
    "#Expose port where shiny app will broadcast\n",
    "<br>\n",
    "<span style='color:RED'> EXPOSE  </span> 3838\n",
    "<br>\n",
    "<span style='color:RED'> RUN  </span> echo \"local({options(shiny.port = 3838, shiny.host = '0.0.0.0')})\" >> /usr/local/lib/R/etc/Rprofile.site\n",
    "<br>\n",
    "<span style='color:RED'> CMD  </span> [\"Rscript\", \"-e\", \"myshinyapp::runApp()\"]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def6761-393b-4531-837a-0ec31ed5cd4a",
   "metadata": {},
   "source": [
    "Une fois l'image créée, nous devons la pousser vers un dépôt. Docker hub offre des dépôts publics qu'on peut utiliser gratuitement. Le publication de l'image peut se faire avec la ligne de commande de Docker : ``docker push image``. Mais c'est recommandé de mettre en place une configuration d'intégration continue pour mettre à jour l'image automatiquement. Le tutoriel Shiny explique en détail l'intégration continue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60eaa7f-0d7e-4809-aeb9-152c68bcaf9f",
   "metadata": {},
   "source": [
    "## 2- Déploiement sur SSP CLoud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bbb24d-ea2d-49f3-a695-51e9c124813c",
   "metadata": {},
   "source": [
    "### Création d'un Chart Helm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3cdf98-e93c-403a-9ecb-e09097ecb25e",
   "metadata": {},
   "source": [
    "Le déploiement de l'application nécessite la création d'un chart Helm. Concrètement, un chart Helm peut être vu comme un package Kubernetes, contenant les ressources nécessaires au déploiement d'une application.\n",
    "\n",
    "Le dépôt de [déploiement] contient un chart Helm permettant le déploiement de l'application template. Ce repository va servir de base pour le chart Helm de votre application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3fbf90f-2eb4-41f5-9e03-096002ce8d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'helm-chart-web-deployment'...\n",
      "remote: Enumerating objects: 16, done.\u001b[K\n",
      "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
      "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
      "remote: Total 16 (delta 0), reused 13 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (16/16), 5.62 KiB | 958.00 KiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/amine-bs/helm-chart-web-deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d4f421-b47b-45f4-abdc-730bcdce64f2",
   "metadata": {},
   "source": [
    "Le fichier ``values.yaml`` contient précisément les valeurs que l'on modifie. Les modifications à apporter dépendent naturellement de ce que réalise en pratique l'application, car cela conditionne les ressources dont elle a besoin. Dans un premier temps, il nous faut modifier :\n",
    "- le chemin et nom de l'image\n",
    "- le tag de l'image. Il s'agit du tag de l'image sur le DockerHub. Par défault, et pendant la phase de développement, on peut indiquer le tag latest pour signifier \"la dernière version de l'image qui a été produite\".\n",
    "- l'hostname de l'Ingress, i.e. l'URL à laquelle l'application sera accessible une fois déployée. Cette URL doit être de la forme *.lab.sspcloud.fr ; par exemple dans notre cas : flask-tuto.lab.sspcloud.fr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3977740-0d41-459c-8dfd-e231cbc4075d",
   "metadata": {},
   "source": [
    "### Utilisation du stockage de données S3 avec MinIO\n",
    "Si votre application n'utilise pas de données externes, ou contient ses propres données dans l'image Docker, vous pouvez donner la valeur false au paramètre ``s3.enabled`` et passer cette section. A l'inverse, si l'application utilise des données en entrée stockées sur ``MinIO``, il faut donner la valeur true au paramètre et fournir à l'application les informations d'authentification au service de stockage. Ces informations sont sensibles, et ne doivent donc jamais figurer en clair dans le code source de l'application ou sur un dépôt GitHub. Pour éviter ce risque, on va inscrire ces informations dans un objet Kubernetes appelé ``Secret``, qui va nous permettre de les passer à l'application sous la forme de variables d'environnement.\n",
    "\n",
    "La première étape est de créer un compte de service sur la console MinIO. Pour ce faire :\n",
    "\n",
    "- menu \"Identity\" -> \"Service Accounts\" -> \"Create Service Account\" -> \"Create\"\n",
    "- comme précédemment, conserver à l'écran les informations de connexion.\n",
    "\n",
    "La seconde étape est de créer un Secret Kubernetes contenant ces informations. Pour être accessible dans l'application, ce secret doit être appliqué comme une ressource dans le namespace Kubernetes dans lequel sera déployé l'application. \n",
    "\n",
    "Pour cela :\n",
    "- Écrire le template suivant dans un fichier quelconque.yaml :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e1939-fb97-4c94-b2db-32562b355b7c",
   "metadata": {},
   "source": [
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: myshinyapp-s3\n",
    "type: Opaque\n",
    "stringData:\n",
    "  AWS_ACCESS_KEY_ID: changeme\n",
    "  AWS_SECRET_ACCESS_KEY: changeme\n",
    "  AWS_S3_ENDPOINT: minio.lab.sspcloud.fr\n",
    "  AWS_DEFAULT_REGION: us-east-1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e0c7da-b7a0-4c44-be84-48eca1c38405",
   "metadata": {},
   "source": [
    "- Les valeurs de ``AWS_ACCESS_KEY_ID`` et ``AWS_SECRET_ACCESS_KEY`` sont à remplacer par les valeurs obtenues à l'étape précédente sur la console MinIO. Les valeurs de ``AWS_S3_ENDPOINT`` et ``AWS_DEFAULT_REGION`` n'ont pas besoin d'être modifiées pour une utilisation sur le cluster. Enfin, le nom du Secret (variable metadata.name) doit porter la même valeur que la variable ``s3.existingSecret``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a880317-e634-41f3-b7ff-1cda2529e390",
   "metadata": {},
   "source": [
    "Pour être accessible dans l'application, ce secret doit être appliqué comme une ressource dans le namespace Kubernetes dans lequel sera déployé l'application. Pour cela :\n",
    "\n",
    "- mettre le template de secret dans un fichier quelconque.yaml et remplacer les valeurs comme indiqué ci-dessus\n",
    "- dans un terminal, exécuter ``kubectl apply -f quelconque.yaml``\n",
    "- si tout a bien fonctionné, un message devrait confirmer la création du secret. Du style secret/nom_de_secret created où nom_de_secret est ce que vous avez renseigné dans metadata.name du fichier quelconque.yaml."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb1424-fe8f-4db5-9413-e4821fda61bc",
   "metadata": {},
   "source": [
    "Une fois le secret appliqué, les quatre variables d'environnement définies dans le secret sont accessibles dans l'application. Vu que ces variables sont standards, il est alors possible de se connecter au stockage MinIO via le package R ``aws.s3`` ou le package Python ``boto3`` sans même avoir besoin de les préciser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132ceffa-3553-43cd-bbdc-baff9fc24db0",
   "metadata": {},
   "source": [
    "### Utilisation d'une base de données PostgreSQL\n",
    "Si votre application n'utilise pas de base PostgreSQL, vous pouvez donner la valeur false au paramètre ``postgresql.enabled`` et passer cette section. Sinon, il faut donner la valeur true au paramètre ``postgresql.enabled``. Il est par ailleurs possible de changer les paramètres ``postgresql.username`` (nom d'utilisateur), ``postgresql.database`` (nom de la base de données) et ``postgresql.fullnameOverride`` (nom de domaine du service PostgreSQL) à sa guise, sachant que ces paramètres seront de toute manière passés automatiquement à l'application sous forme de variables d'environnement.\n",
    "\n",
    "Les mots de passe de connexion, données sensibles, doivent quant à eux être passés à l'application via un Secret Kubernetes. La procédure est la même que précédemment, et le template de Secret à utiliser est :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849bbfc-2319-4cff-bfdf-08a307fda001",
   "metadata": {},
   "source": [
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: myshinyapp-postgresql\n",
    "type: Opaque\n",
    "stringData:\n",
    "  password: changeme\n",
    "  postgres-password: changeme\n",
    "  replication-password: changeme\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e2c7d-c567-40f3-95c9-ef1f1063a0aa",
   "metadata": {},
   "source": [
    "Trois passwords sont nécessaires, mais seul le champ ``stringData.password`` (password utilisateur) sera utilisé en pratique dans l'application. Il est donc possible de fixer le même password pour les trois champs de ``stringData`` sans trop de risque. Là encore, toutes ces informations (valeurs du chart et secrets) seront passées à l'application sous la forme de variables d'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991c3b6-d7cf-441c-a8a8-9a0142a6ff10",
   "metadata": {},
   "source": [
    "### Déploiement du Chart Helm\n",
    "Finalement, pour déployer l'application sur le cluster à partir du terminal d'un service VSCode :\n",
    "\n",
    "- cloner le dépôt contenant le chart de votre application (pas le template)\n",
    "- importer les dépendances avec la commande ``helm dependency update chemin_du_depot_chart``\n",
    "- installer le chart Helm : ``helm install chemin_du_depot_chart --generate-name``\n",
    "Si tout a fonctionné, un message devrait confirmer l'instanciation du chart. On peut vérifier que ce dernier a bien été déployé avec la commande ``helm ls``, qui liste l'ensemble des instances de Chart helm déployées sur le cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
